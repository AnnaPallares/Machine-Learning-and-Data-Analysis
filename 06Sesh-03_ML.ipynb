{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1osZYtF4GuTvhT8zrGpm2TobrN88bJVjC","timestamp":1699616223475},{"file_id":"1iKYP6TNliurUPcUjIweSq6CYkoUKQHgs","timestamp":1699615124589},{"file_id":"1cIYCK-vdJyigNI3fqkJKFGqHcAauMe55","timestamp":1697809774929},{"file_id":"11qP8tLJyT-PXH4eImaBpvcUeVffvCxZf","timestamp":1697808323643}],"toc_visible":true,"authorship_tag":"ABX9TyOn8UyHVHY4duKEbM3PjDDG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Machine Learning and Data Analysis\n","----------------------------------------------\n","### *Session 6.3*\n","\n","\n","```\n","10th November, 2023\n","Anna Pallarès López\n","Computer Engineering Master's\n","\n","```"],"metadata":{"id":"HJaqPYQ7V1fs"}},{"cell_type":"markdown","source":[],"metadata":{"id":"KehLhpTHuDqN"}},{"cell_type":"code","source":["# we first download from the internet the mnist dataset (bw)\n","from sklearn.datasets import fetch_openml\n","mnist = fetch_openml('mnist_784')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUM-gBxJvSNV","executionInfo":{"status":"ok","timestamp":1699616535760,"user_tz":-60,"elapsed":37916,"user":{"displayName":"Anna Pallares Lopez","userId":"02802121497963548737"}},"outputId":"72f96f23-d4ea-47c4-ae82-f8cc5d44605a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]},{"cell_type":"code","source":["X = mnist.data\n","Y = mnist.target\n","X = X.to_numpy()\n","Y = Y.to_numpy()\n","import numpy as np\n","Y = np.asarray([eval(i) for i in Y])\n","from random import sample\n","n = 300\n","nv = 30\n","nt = 1000\n","mask = np.asarray(sample(range(X.shape[0]),n+nv+nt))\n","X = X[mask,:]\n","Y = Y[mask]\n","mask = range(n+nv,n+nv+nt)\n","Xt = X[mask,]\n","Yt = Y[mask]\n","mask = range(n,n+nv)\n","Xv = X[mask,]\n","Yv = Y[mask]\n","mask = range(0,n)\n","X = X[mask,]\n","Y = Y[mask]"],"metadata":{"id":"YVgNaXPSwXYF","executionInfo":{"status":"ok","timestamp":1699617450698,"user_tz":-60,"elapsed":309,"user":{"displayName":"Anna Pallares Lopez","userId":"02802121497963548737"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# xgboost is a better model in respect of random foerst because the intrinsec of the model.\n","# RF is good because its trivial, so its the natural option but has limits\n","# xgboost is very difficult to use because its extremely sensitive to all the parameters that characterise the algorithm\n","\n","import xgboost as xgb\n","\n","# define all the ingridients\n","# parameters list\n","pl = [(\"eta\", 0.08),\n","      (\"max_depth\", 6),\n","      (\"subsamble\", 0.8),\n","      (\"colsample_bytree\", 0.8),\n","      (\"objective\", \"multi:softmax\"),\n","      (\"eval_metric\", \"merror\"),\n","      (\"alpha\", 8),\n","      (\"lambda\", 2),\n","      (\"num_clusters\", 10)]\n","n_rounds = 600 # max number of trees to construt\n","early_stopping = 50 # when i want to stop the gradient descent\n","D = xgb.DMatrix(X,Y) #data for learning\n","Dv = xgb.DMatrix(Xv,Yv) #data for validation\n","print_val = [(D, \"train\"), (Dv, \"validation\")]\n","\n","#now we pass all this mess to xgboost\n","M = xgb.train(pl, D, n_rounds, evals = print_val, early_stopping_rounds = early_stopping, verbose_eval = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"bViJjkJa_Exz","executionInfo":{"status":"error","timestamp":1699617648425,"user_tz":-60,"elapsed":16,"user":{"displayName":"Anna Pallares Lopez","userId":"02802121497963548737"}},"outputId":"0bdb4b80-fc96-469a-8c98-0cfea70f7cb8"},"execution_count":23,"outputs":[{"output_type":"error","ename":"XGBoostError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2ed3d8d68d06>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#now we pass all this mess to xgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mbefore_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;34m\"\"\"Function called before training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"before_training should return the model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mbefore_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_Model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarting_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_boosted_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mnum_boosted_rounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2631\u001b[0m         \u001b[0mrounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2633\u001b[0;31m         \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterBoostedRounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2634\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \"\"\"\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mXGBoostError\u001b[0m: value 0 for Parameter num_class should be greater equal to 1\nnum_class: Number of output class in the multi-class classification."]}]},{"cell_type":"code","source":[],"metadata":{"id":"jx2R7rlnGytL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","pl = [(\"eta\",                0.08),\n","      (\"max_depth\",          6),\n","      (\"subsample\",          0.8),\n","      (\"colsample_bytree\",   0.8),\n","      (\"objective\",          \"multi:softmax\"),\n","      (\"eval_metric\",        \"merror\"),\n","      (\"alpha\",              8),\n","      (\"lambda\",             2),\n","      (\"num_class\",          10)]\n","n_rounds = 600\n","early_stopping = 50\n","D = xgb.DMatrix(X,Y)\n","Dv = xgb.DMatrix(Xv,Yv)\n","print_val = [(D,\"train\"),(Dv,\"validation\")]\n","M = xgb.train(pl, D, n_rounds, evals = print_val,\n","              early_stopping_rounds = early_stopping, verbose_eval = True)"],"metadata":{"id":"XNHqUHvPGM4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","Yp = M.predict(xgb.DMatrix(Xt))\n","err = np.mean(Yp != Yt)\n","print(err)\n","print(confusion_matrix(Yt,Yp))"],"metadata":{"id":"MB2XyEfOBWCS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Its a very powerful library, but not trivial. If we want to use xgboost we can do it but we have to explain everything. THe same with trees, with anatomic bombs...\n","\n","This library is another but we can use skitlean no to do a grid search. They are compatible. However there is also a gs implemented in the xgboost library that does all the search."],"metadata":{"id":"IyERXKp4GiCZ"}},{"cell_type":"code","source":[],"metadata":{"id":"vBDfeg3LBUDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Nx7acaLyAYdq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gfIX0ahnAWI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IbvO3Ph_AD2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WiZ9VwxDAB6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qStoHgkb__N4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RregrA3A-N_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VPlG65Hc757R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D42xA_Jc7kv9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vzsltZDK7jN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"plX_d-pq7gZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hC9BBWr27ILU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z18fBa4T6-9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8eXCG63a659o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"99KVDMDs62dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QWSvh-iD61Lc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v6Pofyel6jWm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dN8SN3m9417e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aTllAWBG13IP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s-uYGKFY1yAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LT-NFzko1nsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aTvCO0kK0qib"},"execution_count":null,"outputs":[]}]}